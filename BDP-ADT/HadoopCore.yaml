tosca_definitions_version: tosca_simple_yaml_1_0

imports:
  - https://raw.githubusercontent.com/micado-scale/tosca/v0.9.0/micado_types.yaml

repositories:
  docker_hub: https://hub.docker.com/

description: ADT for Core Hadoop Cluster on EC2

dsl_definitions:
  compute_properties: &compute_properties
    region_name: us-east-2
    image_id: ami-0d03add87774b12c5
    instance_type: t2.xlarge
    key_name: metacampus
    security_group_ids:
      - sg-07d828def83fa2d70

  endpoint_properties: &endpoint_properties
    interface_cloud: ec2
    root_block_device: {"volume_size": "10"}
    endpoint_cloud: https://ec2.us-east-2.amazonaws.com
  
  slave_properties: &slave_properties
    min_instances: {get_input: min_workers}
    max_instances: {get_input: max_workers}


topology_template:
  inputs:
    min_workers:
      type: integer
      description: Minimum workers and replicas for datanodes and nodemanagers
      required: yes

    max_workers:
      type: integer
      description: Maximum workers and replicas for datanodes and nodemanagers
      required: yes

  node_templates:
    hdfs-namenode:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: apps/v1
              kind: StatefulSet
              metadata:
                name: hdfs-namenode
              spec:
                serviceName: hdfs-namenode
                replicas: 1
                updateStrategy:
                  type: RollingUpdate
                podManagementPolicy: Parallel
                selector:
                  matchLabels:
                      app: hdfs
                      component: namenode
                template:
                  metadata:
                    labels:
                      app: hdfs
                      component: namenode
                  spec:
                    initContainers:
                      - name: hdfs-init
                        image: flokkr/hadoop
                        args: ["hadoop","version"]
                        env:
                          - name: "ENSURE_NAMENODE_DIR"
                            value: "/data/namenode"
                        envFrom:
                          - configMapRef:
                              name: hdfs-config
                        volumeMounts:
                          - name: "data"
                            mountPath: "/data"
                    containers:
                      - name: hdfs-namenode
                        image: flokkr/hadoop
                        args: ["hdfs","namenode"]
                        envFrom:
                          - configMapRef:
                              name: hdfs-config
                        volumeMounts:
                          - name: "data"
                            mountPath: "/data"
                    nodeSelector:
                      micado.eu/node_type: bdp-master
                    volumes:
                      - name: "data"
                        emptyDir: {}

    hdfs-config-configmap:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: ConfigMap
              metadata:
                name: hdfs-config
              data:
                HDFS-SITE.XML_dfs.namenode.name.dir: "/data/namenode"
                HDFS-SITE.XML_dfs.datanode.data.dir: "/data/datanode"
                HDFS-SITE.XML_dfs.namenode.rpc-address: "hdfs-namenode-0.hdfs-namenode:9820"
                HDFS-SITE.XML_dfs.permissions: "false"
                HDFS-SITE.XML_hadoop.tmp.dir: "/tmp"
                LOG4J.PROPERTIES_log4j.rootLogger: "INFO, stdout"
                LOG4J.PROPERTIES_log4j.appender.stdout: "org.apache.log4j.ConsoleAppender"
                LOG4J.PROPERTIES_log4j.appender.stdout.layout: "org.apache.log4j.PatternLayout"
                LOG4J.PROPERTIES_log4j.appender.stdout.layout.ConversionPattern: "%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n"
                CORE-SITE.XML_fs.defaultFS: "hdfs://hdfs-namenode-0.hdfs-namenode:9820"
                CORE-SITE.XML_hadoop.tmp.dir: "/tmp"
                

    hdfs-namenode-public-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: hdfs-namenode-public
              spec:
                ports:
                  - port: 9870
                    nodePort: 30010
                    name: web
                selector:
                  app: hdfs
                  component: namenode
                type: NodePort
    hdfs-namenode-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: hdfs-namenode
              spec:
                clusterIP: None
                ports:
                  - port: 9870
                    name: web
                selector:
                  app: hdfs
                  component: namenode

    hdfs-datanode:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: apps/v1
              kind: StatefulSet
              metadata:
                name: hdfs-datanode
              spec:
                serviceName: hdfs-datanode
                replicas: {get_input: min_workers}
                updateStrategy:
                  type: RollingUpdate
                selector:
                  matchLabels:
                      app: hdfs
                      component: datanode
                podManagementPolicy: Parallel
                template:
                  metadata:
                    labels:
                      app: hdfs
                      component: datanode
                  spec:
                    affinity:
                      podAntiAffinity:
                        requiredDuringSchedulingIgnoredDuringExecution:
                        - labelSelector:
                            matchExpressions:
                              - key: "app"
                                operator: In
                                values:
                                - hdfs
                          topologyKey: "kubernetes.io/hostname"
                    containers:
                      - name: hdfs-datanode
                        image: flokkr/hadoop
                        args: ["hdfs","datanode"]
                        env:
                          - name: "WAITFOR"
                            value: "hdfs-namenode-0.hdfs-namenode:9820"
                        volumeMounts:
                        - name: data
                          mountPath: /data
                        envFrom:
                          - configMapRef:
                              name: hdfs-config
                    nodeSelector:
                      micado.eu/node_type: bdp-slave
                    volumes:
                      - name: config
                        configMap:
                          name: hdfs-config
                      - name: "data"
                        emptyDir: {}

    hdfs-datanode-public-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: hdfs-datanode-public
              spec:
                ports:
                  - port: 9874
                    nodePort: 30020
                    name: web
                selector:
                  app: hdfs
                  component: datanode
                type: NodePort

    hdfs-datanode-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: hdfs-datanode
              spec:
                ports:
                  - port: 9874
                    name: web
                clusterIP: None
                selector:
                  app: hdfs
                  component: datanode

    yarn-resourcemanager:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: apps/v1
              kind: StatefulSet
              metadata:
                name: yarn-resourcemanager
                labels:
                  app: yarn
                  component: resourcemanager
              spec:
                serviceName: yarn-resourcemanager
                replicas: 1
                updateStrategy:
                  type: RollingUpdate
                podManagementPolicy: Parallel
                selector:
                  matchLabels:
                      app: yarn
                      component: resourcemanager
                template:
                  metadata:
                    labels:
                      app: yarn
                      component: resourcemanager
                  spec:
                    containers:
                      - name: yarn-resourcemanager
                        image: flokkr/hadoop
                        args: ["yarn","resourcemanager"]
                        envFrom:
                          - configMapRef:
                              name: yarn-config
                          - configMapRef:
                              name: hdfs-config
                    nodeSelector:
                      micado.eu/node_type: bdp-master
                    volumes:
                      - name: config
                        configMap:
                          name: yarn-config
                      - name: "data"
                        emptyDir: {}

    yarn-config-configmap:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: ConfigMap
              metadata:
                name: yarn-config
              data:
                MAPRED-SITE.XML_mapreduce.framework.name: "yarn"
                MAPRED-SITE.XML_yarn.app.mapreduce.am.env: "HADOOP_MAPRED_HOME=/opt/hadoop"
                MAPRED-SITE.XML_mapreduce.map.env: "HADOOP_MAPRED_HOME=/opt/hadoop"
                MAPRED-SITE.XML_mapreduce.reduce.env: "HADOOP_MAPRED_HOME=/opt/hadoop"
                YARN-SITE.XML_yarn.resourcemanager.hostname: "yarn-resourcemanager-0.yarn-resourcemanager"
                YARN-SITE.XML_yarn.resourcemanager.bind-host: "0.0.0.0"
                YARN-SITE.XML_yarn.nodemanager.bind-host: "0.0.0.0"
                YARN-SITE.XML_yarn.webapp.ui2.enable: "true"
                YARN-SITE.XML_yarn.nodemanager.pmem-check-enabled: "false"
                YARN-SITE.XML_yarn.nodemanager.delete.debug-delay-sec: "600"
                YARN-SITE.XML_yarn.nodemanager.vmem-check-enabled: "false"
                YARN-SITE.XML_yarn.nodemanager.aux-services: "mapreduce_shuffle"
                YARN-SITE.XML_yarn.nodemanager.auxservices.mapreduce.shuffle.class: "org.apache.hadoop.mapred.ShuffleHandler"
                YARN_SITE.XML_yarn.timeline-service.hostname: yarn-timeline-0.yarn-timeline
                YARN_SITE.XML_yarn.log.server.url: http://yarn-timeline-0.yarn-timeline:8188/applicationhistory/logs/
                YARN-SITE.XML_yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage: "95"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.maximum-applications: "10000"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.maximum-am-resource-percent: "0.1"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.resource-calculator: "org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.queues: "default"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.capacity: "100"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.user-limit-factor: "1"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.maximum-capacity: "100"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.state: "RUNNING"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.acl_submit_applications: "*"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.acl_administer_queue: "*"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.node-locality-delay: "40"
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.queue-mappings: ""
                CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.queue-mappings-override.enable: "false"

    yarn-resourcemanager-public-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: yarn-resourcemanager-public
              spec:
                ports:
                  - port: 8088
                    nodePort: 30040
                    name: web
                selector:
                  app: yarn
                  component: resourcemanager
                type: NodePort

    yarn-resourcemanager-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: yarn-resourcemanager
              spec:
                ports:
                  - port: 8088
                    name: web
                clusterIP: None
                selector:
                  app: yarn
                  component: resourcemanager

    yarn-nodemanager:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: apps/v1
              kind: StatefulSet
              metadata:
                name: yarn-nodemanager
                labels:
                  app: yarn
                  component: nodemanager
              spec:
                serviceName: yarn-nodemanager
                replicas: {get_input: min_workers}
                updateStrategy:
                  type: RollingUpdate
                podManagementPolicy: Parallel
                selector:
                  matchLabels:
                      app: yarn
                      component: nodemanager
                template:
                  metadata:
                    labels:
                      app: yarn
                      component: nodemanager
                  spec:
                    affinity:
                      podAntiAffinity:
                        requiredDuringSchedulingIgnoredDuringExecution:
                        - labelSelector:
                            matchExpressions:
                              - key: "app"
                                operator: In
                                values:
                                - yarn
                          topologyKey: "kubernetes.io/hostname"
                    containers:
                      - name: yarn-nodemanager
                        image: flokkr/hadoop
                        args: ["yarn","nodemanager"]
                        env:
                            - name: WAITFOR
                              value: "yarn-resourcemanager-0.yarn-resourcemanager:8031"
                        envFrom:
                          - configMapRef:
                              name: yarn-config
                          - configMapRef:
                              name: hdfs-config
                        volumeMounts:
                          - name: "data"
                            mountPath: "/data"
                    nodeSelector:
                      micado.eu/node_type: bdp-slave
                    volumes:
                      - name: "data"
                        emptyDir: {}

    yarn-nodemanager-public-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: yarn-nodemanager-public
              spec:
                ports:
                  - port: 8042
                    nodePort: 30030
                    name: web
                selector:
                  app: yarn
                  component: nodemanager
                type: NodePort

    yarn-nodemanager-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: yarn-nodemanager
              spec:
                clusterIP: None
                ports:
                  - port: 8042
                    name: web
                selector:
                  app: yarn
                  component: nodemanager

    yarn-timeline:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: apps/v1
              kind: StatefulSet
              metadata:
                name: yarn-timeline
                labels:
                  app: yarn
                  component: timeline
              spec:
                serviceName: yarn-timeline
                replicas: 1
                updateStrategy:
                  type: RollingUpdate
                podManagementPolicy: Parallel
                selector:
                  matchLabels:
                      app: yarn
                      component: timeline
                template:
                  metadata:
                    labels:
                      app: yarn
                      component: timeline
                  spec:
                    containers:
                      - name: yarn-timeline
                        image: flokkr/hadoop
                        args: ["yarn","timelineserver"]
                        envFrom:
                          - configMapRef:
                              name: yarn-config
                          - configMapRef:
                              name: hdfs-config
                        volumeMounts:
                          - name: data
                            mountPath: /data
                    nodeSelector:
                      micado.eu/node_type: bdp-master
                    volumes:
                      - name: data
                        emptyDir: {}
              
    yarn-timeline-public-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: yarn-timeline-public
              spec:
                ports:
                  - port: 8188
                    nodePort: 30050
                    name: web
                selector:
                  app: yarn
                  component: timeline
                type: NodePort

    yarn-timeline-service:
      type: tosca.nodes.MiCADO.Kubernetes
      interfaces:
        Kubernetes:
          create:
            inputs:
              apiVersion: v1
              kind: Service
              metadata:
                name: yarn-timeline
              spec:
                clusterIP: None
                ports:
                  - port: 8188
                    name: web
                selector:
                  app: yarn
                  component: timeline
             
    bdp-master:
      type: tosca.nodes.MiCADO.EC2.Compute
      properties: *compute_properties
      interfaces:
        Terraform:
          create:
            inputs: *endpoint_properties

    bdp-slave:
      type: tosca.nodes.MiCADO.EC2.Compute
      properties: *compute_properties
      interfaces:
        Terraform:
          create:
            inputs: *endpoint_properties
      capabilities:
        scalable:
          properties: *slave_properties

  policies:
    - monitoring:
        type: tosca.policies.Monitoring.MiCADO
        properties:
          enable_container_metrics: true
          enable_node_metrics: true
    - scalability:
        type: tosca.policies.Scaling.MiCADO.VirtualMachine.CPU.datanode
        targets: [ bdp-slave ]
        properties:
          constants:
            NODE_NAME: 'bdp-slave'
            NODE_TH_MAX: '60'
            NODE_TH_MIN: '0'
          min_instances: {get_input: min_workers}
          max_instances: {get_input: max_workers}
    - scalability:
        type: tosca.policies.Scaling.MiCADO.Container.CPU.datanode
        targets: [ hdfs-datanode ]
        properties:
          constants:
            SERVICE_NAME: 'hdfs-datanode'
            SERVICE_FULL_NAME: 'hdfs-datanode'
            SERVICE_TH_MAX: '60'
            SERVICE_TH_MIN: '0'
          min_instances: {get_input: min_workers}
          max_instances: {get_input: max_workers}
    - scalability:
        type: tosca.policies.Scaling.MiCADO.Container.CPU.nodemanager
        targets: [ yarn-nodemanager ]
        properties:
          constants:
            SERVICE_NAME: 'yarn-nodemanager'
            SERVICE_FULL_NAME: 'yarn-nodemanager'
            SERVICE_TH_MAX: '60'
            SERVICE_TH_MIN: '0'
          min_instances: {get_input: min_workers}
          max_instances: {get_input: max_workers}

policy_types:
  tosca.policies.Scaling.MiCADO.Container.CPU.datanode:
    derived_from: tosca.policies.Scaling.MiCADO
    description: base MiCADO policy defining data sources, constants, queries, alerts, limits and rules
    properties:
      alerts:
        type: list
        description: pre-define alerts for container CPU
        default:
        - alert: service_overloaded
          expr: 'avg(rate(container_cpu_usage_seconds_total{container_label_io_kubernetes_container_name="{{SERVICE_FULL_NAME}}"}[60s]))*100 > {{SERVICE_TH_MAX}}'
          for: 30s
        - alert: service_underloaded
          expr: 'avg(rate(container_cpu_usage_seconds_total{container_label_io_kubernetes_container_name="{{SERVICE_FULL_NAME}}"}[60s]))*100 < {{SERVICE_TH_MIN}}'
          for: 30s
        required: true
      scaling_rule:
        type: string
        description: pre-define scaling rule for container CPU
        default: |
          if len(m_nodes) == m_node_count:
            if service_overloaded or m_node_count > m_container_count:
              m_container_count+=1
            if service_underloaded:
              m_container_count-=1
          else:
            print('Transient phase, skipping update of containers...')
        required: true

  tosca.policies.Scaling.MiCADO.Container.CPU.nodemanager:
    derived_from: tosca.policies.Scaling.MiCADO
    description: base MiCADO policy defining data sources, constants, queries, alerts, limits and rules
    properties:
      alerts:
        type: list
        description: pre-define alerts for container CPU
        default:
        - alert: service_overloaded
          expr: 'avg(rate(container_cpu_usage_seconds_total{container_label_io_kubernetes_container_name="{{SERVICE_FULL_NAME}}"}[60s]))*100 > {{SERVICE_TH_MAX}}'
          for: 30s
        - alert: service_underloaded
          expr: 'avg(rate(container_cpu_usage_seconds_total{container_label_io_kubernetes_container_name="{{SERVICE_FULL_NAME}}"}[60s]))*100 < {{SERVICE_TH_MIN}}'
          for: 30s
        required: true
      scaling_rule:
        type: string
        description: pre-define scaling rule for container CPU
        default: |
          if len(m_nodes) == m_node_count:
            if service_overloaded or m_node_count > m_container_count:
              m_container_count+=1
            if service_underloaded:
              m_container_count-=1
          else:
            print('Transient phase, skipping update of containers...')
        required: true

  tosca.policies.Scaling.MiCADO.VirtualMachine.CPU.datanode:
    derived_from: tosca.policies.Scaling.MiCADO
    description: CPU-based VM scaling policy
    properties:
      alerts:
        type: list
        description: pre-define alerts for VM CPU
        default:
        - alert: node_overloaded
          expr: '(100-(avg(rate(node_cpu_seconds_total{node="{{ NODE_NAME }}", mode="idle"}[60s]))*100)) > {{NODE_TH_MAX}}'
          for: 1m
        - alert: node_underloaded
          expr: '(100-(avg(rate(node_cpu_seconds_total{node="{{ NODE_NAME }}", mode="idle"}[60s]))*100)) < {{NODE_TH_MIN}}'
          for: 1m
        required: true
      scaling_rule:
        type: string
        description: pre-define scaling rule for VM CPU
        default: |
          if len(m_nodes) <= m_node_count and m_time_since_node_count_changed > 60:
            if node_overloaded:
              m_node_count+=1
            if node_underloaded:
              m_node_count-=1
          else:
            print('Transient phase, skipping update of nodes...')
        required: true